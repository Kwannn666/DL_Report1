{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190ed74f-7b21-4f9f-a036-171c80fad002",
   "metadata": {},
   "source": [
    "# Task A - All-in-One Notebook: Dynamic Convolution Module with Full Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44304253-637d-41f5-9987-8e9267f88d85",
   "metadata": {},
   "source": [
    "# 載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f609452-0620-4780-a898-db66dce1e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from thop import profile\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c2ea32-2c77-4213-a122-d87799f65fee",
   "metadata": {},
   "source": [
    "# 自定義通道選擇設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11d275c3-98e4-4acf-bdcf-011d62289094",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "channel_dict = {\"R\": 0, \"G\": 1, \"B\": 2}\n",
    "\n",
    "def get_channel_mask(combo, batch_size):\n",
    "    mask = torch.zeros((batch_size, 3))\n",
    "    for c in combo:\n",
    "        mask[:, channel_dict[c]] = 1\n",
    "    return mask.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94fab18-3a4d-45a9-bdc8-28f188eacc49",
   "metadata": {},
   "source": [
    "# 資料集設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d70027-f6f5-48ba-bce3-7755dcdf2358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetMiniDataset(Dataset):\n",
    "    def __init__(self, txt_file, img_dir, transform=None):\n",
    "        self.img_labels = []\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        with open(txt_file, 'r') as f:\n",
    "            for line in f:\n",
    "                path, label = line.strip().split()\n",
    "                self.img_labels.append((path, int(label)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.img_labels[idx]\n",
    "        image = Image.open(os.path.join(self.img_dir, img_path)).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8fda41-d472-4ea7-90c3-1c096e2bb9a6",
   "metadata": {},
   "source": [
    "# 動態捲積"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d61a7e4-9d61-4a77-84ac-a8f8e84d7ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicConv(nn.Module):\n",
    "    def __init__(self, max_in_channels, out_channels, hidden_dim=64, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.max_in_channels = max_in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.weight_gen = nn.Sequential(\n",
    "            nn.Linear(max_in_channels, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_channels * max_in_channels * kernel_size * kernel_size)\n",
    "        )\n",
    "        self.bias = nn.Parameter(torch.zeros(out_channels))\n",
    "\n",
    "    def forward(self, x, channel_mask):\n",
    "        B, C, H, W = x.size()\n",
    "        padded = torch.zeros((B, self.max_in_channels, H, W), device=x.device)\n",
    "        padded[:, :C] = x\n",
    "        weights = self.weight_gen(channel_mask)\n",
    "        weights = weights.view(B, self.out_channels, self.max_in_channels, self.kernel_size, self.kernel_size)\n",
    "        out = []\n",
    "        for i in range(B):\n",
    "            weight_i = weights[i, :, :C, :, :]\n",
    "            out_i = F.conv2d(x[i:i+1], weight_i, bias=self.bias, padding=self.kernel_size // 2)\n",
    "            out.append(out_i)\n",
    "        return torch.cat(out, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f153d852-4c5a-46c9-b7e3-8fcd0a1f18f8",
   "metadata": {},
   "source": [
    "# 分類器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9513f681-f48a-43fc-a5c7-8643e8bf9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyClassifier(nn.Module):\n",
    "    def __init__(self, conv_layer, num_classes, feature_dim=16):\n",
    "        super().__init__()\n",
    "        self.conv = conv_layer\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, channel_mask):\n",
    "        x = self.conv(x, channel_mask)\n",
    "        x = self.pool(x).squeeze(-1).squeeze(-1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b733d919-8401-4fdc-baea-c73959a1a3fa",
   "metadata": {},
   "source": [
    "# Baseline CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0631f855-695b-40c5-a70c-d579cb5d2bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_baseline(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x).argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d955bd9d-ed89-4636-935c-93eb918a3fd9",
   "metadata": {},
   "source": [
    "# 評估函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac3cdc37-ef32-4e80-9499-420d06ea59f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, combo):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    for x, y in dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        channel_mask = get_channel_mask(combo, x.size(0))\n",
    "        pred = model(x, channel_mask).argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e2486c-67f0-4256-9031-8b3e3158a7af",
   "metadata": {},
   "source": [
    "# 程式主流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a307fb5e-af96-4c58-9a21-462d0b2712e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline(img_dir, transform, epochs=4):\n",
    "    print(\"⇒ Training Static Baseline (RGB only)\")\n",
    "    # 資料\n",
    "    train_ds = ImageNetMiniDataset(os.path.join(img_dir,\"train.txt\"), img_dir, transform)\n",
    "    val_ds   = ImageNetMiniDataset(os.path.join(img_dir,\"val.txt\"),   img_dir, transform)\n",
    "    test_ds  = ImageNetMiniDataset(os.path.join(img_dir,\"test.txt\"),  img_dir, transform)\n",
    "    train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=128)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=128)\n",
    "\n",
    "    model = StaticConvNet(num_classes=50).to(device)\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in tqdm(train_loader, desc=f\"Baseline Epoch {ep+1}\"):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            opt.zero_grad()\n",
    "            loss_fn(model(x), y).backward()\n",
    "            opt.step()\n",
    "\n",
    "    val_acc  = evaluate_baseline(model, val_loader)\n",
    "    test_acc = evaluate_baseline(model, test_loader)\n",
    "    # FLOPs / Params\n",
    "    dummy = torch.randn(1,3,32,32).to(device)\n",
    "    flops, params = profile(model, inputs=(dummy,), verbose=False)\n",
    "    return {\n",
    "        \"combo\":\"RGB\", \"model\":\"StaticBaseline\",\n",
    "        \"hidden_dim\":None, \"out_channels\":None,\n",
    "        \"val_acc\":val_acc, \"test_acc\":test_acc,\n",
    "        \"FLOPs(M)\":flops/1e6, \"Params(K)\":params/1e3\n",
    "    }\n",
    "\n",
    "def run_flexible_dynamicconv_combinations(img_dir, transform, hyper_configs, num_classes=50, epochs=4):\n",
    "    channel_combos = [\"RGB\", \"RG\", \"RB\", \"GB\", \"R\", \"G\", \"B\"]\n",
    "    results = []\n",
    "\n",
    "    for hidden_dim, out_ch in hyper_configs:\n",
    "        print(f\"\\nTraining: hidden_dim={hidden_dim}, out_channels={out_ch}\")\n",
    "        # 構建模型\n",
    "        conv = DynamicConv(max_in_channels=3, out_channels=out_ch, hidden_dim=hidden_dim)\n",
    "        model = ToyClassifier(conv, num_classes=num_classes, feature_dim=out_ch).to(device)\n",
    "\n",
    "        # 讀資料\n",
    "        train_set = ImageNetMiniDataset(os.path.join(img_dir, \"train.txt\"), img_dir, transform)\n",
    "        train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        scaler = GradScaler()\n",
    "\n",
    "        # 訓練\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            pbar = tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\")\n",
    "            for x, y in pbar:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with autocast():\n",
    "                    mask = get_channel_mask(\"RGB\", x.size(0))\n",
    "                    pred = model(x, mask)\n",
    "                    loss = loss_fn(pred, y)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "        # 對每個通道組合分別算 val_acc 和 test_acc\n",
    "        for combo in channel_combos:\n",
    "            # 建立該 combo 的 val loader\n",
    "            val_set_combo  = ImageNetMiniDataset(os.path.join(img_dir, \"val.txt\"), img_dir, transform)\n",
    "            val_loader_combo = DataLoader(val_set_combo, batch_size=128)\n",
    "            val_acc_combo = evaluate(model, val_loader_combo, combo)\n",
    "\n",
    "            # 建立該 combo 的 test loader\n",
    "            test_set_combo  = ImageNetMiniDataset(os.path.join(img_dir, \"test.txt\"), img_dir, transform)\n",
    "            test_loader_combo = DataLoader(test_set_combo, batch_size=128)\n",
    "            test_acc_combo = evaluate(model, test_loader_combo, combo)\n",
    "\n",
    "            # 計算 FLOPs & Params\n",
    "            dummy_input = torch.randn(1, len(combo), 32, 32).to(device)\n",
    "            channel_mask = get_channel_mask(combo, 1)\n",
    "            class WrappedModel(nn.Module):\n",
    "                def __init__(self, model, channel_mask):\n",
    "                    super().__init__()\n",
    "                    self.model = model\n",
    "                    self.channel_mask = channel_mask\n",
    "                def forward(self, x):\n",
    "                    return self.model(x, self.channel_mask)\n",
    "\n",
    "            wrapped_model = WrappedModel(model, channel_mask)\n",
    "            flops, params = profile(wrapped_model, inputs=(dummy_input,), verbose=False)\n",
    "\n",
    "            # 收集結果\n",
    "            results.append({\n",
    "                \"combo\": combo,\n",
    "                \"hidden_dim\": hidden_dim,\n",
    "                \"out_channels\": out_ch,\n",
    "                \"model\": \"DynamicConv\",\n",
    "                \"val_acc\":  val_acc_combo,\n",
    "                \"test_acc\": test_acc_combo,\n",
    "                \"FLOPs(M)\": flops  / 1e6,\n",
    "                \"Params(K)\": params / 1e3\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(\"flexible_dynamicconv_result.csv\", index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c8897-3787-447c-ac1c-9d0de0669913",
   "metadata": {},
   "source": [
    "# 執行程式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37314f61-9695-4ed3-ab10-589ddf58833a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: hidden_dim=64, out_channels=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|████████████████████████████████████████████████████| 495/495 [02:35<00:00,  3.19it/s, loss=3.8102]\n",
      "Train Epoch 2: 100%|████████████████████████████████████████████████████| 495/495 [02:32<00:00,  3.24it/s, loss=3.6991]\n",
      "Train Epoch 3: 100%|████████████████████████████████████████████████████| 495/495 [02:26<00:00,  3.38it/s, loss=3.7186]\n",
      "Train Epoch 4: 100%|████████████████████████████████████████████████████| 495/495 [02:26<00:00,  3.38it/s, loss=3.8359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: hidden_dim=64, out_channels=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|████████████████████████████████████████████████████| 495/495 [02:35<00:00,  3.19it/s, loss=3.8109]\n",
      "Train Epoch 2: 100%|████████████████████████████████████████████████████| 495/495 [02:34<00:00,  3.20it/s, loss=3.7933]\n",
      "Train Epoch 3: 100%|████████████████████████████████████████████████████| 495/495 [02:32<00:00,  3.24it/s, loss=3.8117]\n",
      "Train Epoch 4: 100%|████████████████████████████████████████████████████| 495/495 [02:32<00:00,  3.24it/s, loss=3.8286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: hidden_dim=64, out_channels=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|████████████████████████████████████████████████████| 495/495 [02:29<00:00,  3.32it/s, loss=3.7994]\n",
      "Train Epoch 2: 100%|████████████████████████████████████████████████████| 495/495 [02:32<00:00,  3.24it/s, loss=3.7479]\n",
      "Train Epoch 3: 100%|████████████████████████████████████████████████████| 495/495 [02:29<00:00,  3.30it/s, loss=3.9405]\n",
      "Train Epoch 4: 100%|████████████████████████████████████████████████████| 495/495 [02:33<00:00,  3.23it/s, loss=3.6185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: hidden_dim=128, out_channels=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|████████████████████████████████████████████████████| 495/495 [02:24<00:00,  3.43it/s, loss=3.8196]\n",
      "Train Epoch 2: 100%|████████████████████████████████████████████████████| 495/495 [02:25<00:00,  3.41it/s, loss=3.8034]\n",
      "Train Epoch 3: 100%|████████████████████████████████████████████████████| 495/495 [02:28<00:00,  3.32it/s, loss=3.8102]\n",
      "Train Epoch 4: 100%|████████████████████████████████████████████████████| 495/495 [02:29<00:00,  3.31it/s, loss=3.7134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: hidden_dim=128, out_channels=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|████████████████████████████████████████████████████| 495/495 [02:33<00:00,  3.22it/s, loss=3.7998]\n",
      "Train Epoch 2: 100%|████████████████████████████████████████████████████| 495/495 [02:31<00:00,  3.26it/s, loss=3.7791]\n",
      "Train Epoch 3: 100%|████████████████████████████████████████████████████| 495/495 [02:32<00:00,  3.25it/s, loss=3.7711]\n",
      "Train Epoch 4: 100%|████████████████████████████████████████████████████| 495/495 [02:32<00:00,  3.25it/s, loss=3.7510]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: hidden_dim=128, out_channels=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|████████████████████████████████████████████████████| 495/495 [02:34<00:00,  3.20it/s, loss=3.8955]\n",
      "Train Epoch 2: 100%|████████████████████████████████████████████████████| 495/495 [02:34<00:00,  3.21it/s, loss=3.7676]\n",
      "Train Epoch 3: 100%|████████████████████████████████████████████████████| 495/495 [02:31<00:00,  3.27it/s, loss=3.6875]\n",
      "Train Epoch 4: 100%|████████████████████████████████████████████████████| 495/495 [02:31<00:00,  3.27it/s, loss=3.8391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⇒ Training Static Baseline (RGB only)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline Epoch 1: 100%|██████████████████████████████████████████████████████████████| 495/495 [01:48<00:00,  4.56it/s]\n",
      "Baseline Epoch 2: 100%|██████████████████████████████████████████████████████████████| 495/495 [01:47<00:00,  4.59it/s]\n",
      "Baseline Epoch 3: 100%|██████████████████████████████████████████████████████████████| 495/495 [01:47<00:00,  4.60it/s]\n",
      "Baseline Epoch 4: 100%|██████████████████████████████████████████████████████████████| 495/495 [01:46<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   combo hidden_dim out_channels           model   val_acc  test_acc  \\\n",
      "0    RGB         64           32     DynamicConv  4.444444  5.555556   \n",
      "1     RG         64           32     DynamicConv  5.777778  5.333333   \n",
      "2     RB         64           32     DynamicConv  6.444444  4.000000   \n",
      "3     GB         64           32     DynamicConv  4.666667  5.111111   \n",
      "4      R         64           32     DynamicConv  4.222222  4.000000   \n",
      "5      G         64           32     DynamicConv  5.111111  4.444444   \n",
      "6      B         64           32     DynamicConv  5.333333  5.111111   \n",
      "7    RGB         64           64     DynamicConv  5.777778  6.222222   \n",
      "8     RG         64           64     DynamicConv  5.777778  6.444444   \n",
      "9     RB         64           64     DynamicConv  7.111111  4.666667   \n",
      "10    GB         64           64     DynamicConv  4.000000  6.000000   \n",
      "11     R         64           64     DynamicConv  5.555556  5.333333   \n",
      "12     G         64           64     DynamicConv  4.444444  5.555556   \n",
      "13     B         64           64     DynamicConv  5.111111  3.777778   \n",
      "14   RGB         64          128     DynamicConv  5.555556  6.666667   \n",
      "15    RG         64          128     DynamicConv  5.333333  6.666667   \n",
      "16    RB         64          128     DynamicConv  6.888889  6.222222   \n",
      "17    GB         64          128     DynamicConv  5.333333  7.111111   \n",
      "18     R         64          128     DynamicConv  6.222222  5.555556   \n",
      "19     G         64          128     DynamicConv  6.444444  4.444444   \n",
      "20     B         64          128     DynamicConv  6.444444  6.444444   \n",
      "21   RGB        128           32     DynamicConv  5.555556  6.888889   \n",
      "22    RG        128           32     DynamicConv  4.444444  7.111111   \n",
      "23    RB        128           32     DynamicConv  4.888889  6.000000   \n",
      "24    GB        128           32     DynamicConv  5.777778  5.333333   \n",
      "25     R        128           32     DynamicConv  4.444444  5.777778   \n",
      "26     G        128           32     DynamicConv  5.111111  6.000000   \n",
      "27     B        128           32     DynamicConv  5.111111  6.222222   \n",
      "28   RGB        128           64     DynamicConv  5.333333  7.333333   \n",
      "29    RG        128           64     DynamicConv  4.444444  6.000000   \n",
      "30    RB        128           64     DynamicConv  4.000000  6.888889   \n",
      "31    GB        128           64     DynamicConv  4.666667  7.777778   \n",
      "32     R        128           64     DynamicConv  4.000000  6.000000   \n",
      "33     G        128           64     DynamicConv  4.444444  5.555556   \n",
      "34     B        128           64     DynamicConv  4.444444  6.444444   \n",
      "35   RGB        128          128     DynamicConv  4.666667  8.222222   \n",
      "36    RG        128          128     DynamicConv  5.777778  7.777778   \n",
      "37    RB        128          128     DynamicConv  5.777778  7.333333   \n",
      "38    GB        128          128     DynamicConv  5.777778  7.555556   \n",
      "39     R        128          128     DynamicConv  5.333333  7.333333   \n",
      "40     G        128          128     DynamicConv  4.222222  6.666667   \n",
      "41     B        128          128     DynamicConv  6.222222  7.111111   \n",
      "42   RGB       None         None  StaticBaseline  7.555556  5.777778   \n",
      "\n",
      "    FLOPs(M)  Params(K)  \n",
      "0   0.089888     58.066  \n",
      "1   0.089888     58.066  \n",
      "2   0.089888     58.066  \n",
      "3   0.089888     58.066  \n",
      "4   0.089888     58.066  \n",
      "5   0.089888     58.066  \n",
      "6   0.089888     58.066  \n",
      "7   0.179584    115.826  \n",
      "8   0.179584    115.826  \n",
      "9   0.179584    115.826  \n",
      "10  0.179584    115.826  \n",
      "11  0.179584    115.826  \n",
      "12  0.179584    115.826  \n",
      "13  0.179584    115.826  \n",
      "14  0.358976    231.346  \n",
      "15  0.358976    231.346  \n",
      "16  0.358976    231.346  \n",
      "17  0.358976    231.346  \n",
      "18  0.358976    231.346  \n",
      "19  0.358976    231.346  \n",
      "20  0.358976    231.346  \n",
      "21  0.145376    113.618  \n",
      "22  0.145376    113.618  \n",
      "23  0.145376    113.618  \n",
      "24  0.145376    113.618  \n",
      "25  0.145376    113.618  \n",
      "26  0.145376    113.618  \n",
      "27  0.145376    113.618  \n",
      "28  0.290368    226.674  \n",
      "29  0.290368    226.674  \n",
      "30  0.290368    226.674  \n",
      "31  0.290368    226.674  \n",
      "32  0.290368    226.674  \n",
      "33  0.290368    226.674  \n",
      "34  0.290368    226.674  \n",
      "35  0.580352    452.786  \n",
      "36  0.580352    452.786  \n",
      "37  0.580352    452.786  \n",
      "38  0.580352    452.786  \n",
      "39  0.580352    452.786  \n",
      "40  0.580352    452.786  \n",
      "41  0.580352    452.786  \n",
      "42  1.838272      5.042  \n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "img_dir = \"C:/Users/james/Desktop/DL_Report1/image\"\n",
    "hyper_configs = [(64, 32), (64, 64), (64, 128), (128, 32), (128, 64), (128, 128)]\n",
    "df_flex = run_flexible_dynamicconv_combinations(img_dir, transform, hyper_configs)\n",
    "df_base = pd.DataFrame([run_baseline(img_dir, transform)])\n",
    "df_all = pd.concat([df_flex, df_base], ignore_index=True)\n",
    "df_all.to_csv(\"final_comparison_result.csv\", index=False)\n",
    "print(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53979709-c9cd-4113-9c90-816bc96ae9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
